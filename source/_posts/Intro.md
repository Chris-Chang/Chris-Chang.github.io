---
title: 【置顶】博客介绍
mathjax: false
tags: Intro
categories: Intro
type: others
filename: Intro
date: 2021-05-12 22:53:47
top: 1
---
硕士期间研究方向为数据挖掘，会在此记录自己从小白开始的日常学习内容，也方便向我敬爱的导师汇报学习进度O(∩_∩)O~。

---



目前计划开学前将机器学习和数据挖掘内容初步系统学习一遍。计划完成如下内容的学习：

- 斯坦福吴恩达教授（Andrew Ng ）的[Coursera课程](https://www.coursera.org/learn/machine-learning/home/welcome)（按照课时进度；当前：week3，20%）
- [Introduction to Data Mining, Second Edition. Pang-Ning Tan](https://book.douban.com/subject/20056013/)
- 《数据挖掘导论》（上述第一版中文版，范明，范宏建等译）（每天一小节不等；当前：chap05，100%）
- 周志华《机器学习》（尚未开始）
- 华盛顿大学《机器学习》（Ng的视频看完后开始）

---

<!--more -->

机器学习课程和数据挖掘导论书籍所做的笔记列表如下，每周不定时更新。~~后期会考虑制作成gitbook，放在博客的笔记栏目中（弄了几天没搞成╮(╯▽╰)╭，先放放）~~ 现改成思维导图形式，方便复习和构建整体系统框架。

## 机器学习

- WEEK01-介绍
  - [1.1 什么是机器学习](https://changzhi.space/ML/What%20is%20Machine%20Learning/)
  - [1.2 监督学习](https://changzhi.space/ML/Supervised%20Learning/)
  - [1.3 无监督学习](https://changzhi.space/ML/Unsupervised%20Learning/)
  - [1.4 监督学习的流程](https://changzhi.space/ML/Model%20Representation/)
  - [1.5 代价函数](https://changzhi.space/ML/Cost%20Function%20Intuition%20I/)
  - [1.6 代价函数概述 I](https://changzhi.space/ML/Cost%20Function/)
  - [1.7 代价函数概述 II](https://changzhi.space/ML/Cost%20Function%20Intuition%20II/)
  - [1.8 梯度下降](https://changzhi.space/ML/Gradient%20Descent/)
  - [1.9 梯度下降概述](https://changzhi.space/ML/Gradient%20Descent%20Intuition/)
  - [1.10 线性回归的梯度下降](https://changzhi.space/ML/Gradient%20Descent%20For%20Linear%20Regression/)
- WEEK02
  - [2.1 课程环境搭建](https://changzhi.space/ML/环境搭建/)
  - 2.2- 多元线性回归
    - [2.2.1 多重特征量](https://changzhi.space/ML/多重特征量)
    - [2.2.2 多变量的梯度下降](https://changzhi.space/ML/多变量的梯度下降/)
    - [2.2.3 特征缩放法](https://changzhi.space/ML/特征缩放法)

## 数据挖掘

- chap01- 概述
  - [1.1 什么是数据挖掘](https://changzhi.space/DM/什么是数据挖掘/)
  - [1.2 数据挖掘要解决的问题](https://changzhi.space/DM/数据挖掘要解决的问题)
  - [1.3 数据挖掘的起源](https://changzhi.space/DM/数据挖掘的起源/)
  - [1.4 数据挖掘的任务](https://changzhi.space/DM/数据挖掘的任务/)
- chap02 - 数据
  - 1 - 数据的类型
    - [2.1.1 属性和度量](https://changzhi.space/DM/属性和度量/)
    - [2.1.2 数据集的类型](https://changzhi.space/DM/数据集的类型/)
  - 2- 数据质量
    - [2.2.1 测量和数据收集问题](https://changzhi.space/DM/%E6%B5%8B%E9%87%8F%E5%92%8C%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E9%97%AE%E9%A2%98/)
    - [2.2.2 关于应用的问题](https://changzhi.space/DM/关于应用的问题/)
  - 3 - [数据预处理](https://changzhi.space/DM/数据预处理/)
    - [聚集](https://changzhi.space/DM/聚集/)
    - [抽样](https://changzhi.space/DM/抽样/)
  - 4 - [相似性和相异性的度量](https://changzhi.space/DM/相似性和相异性的度量/)
    - [2.4.1 基础](https://changzhi.space/DM/2.4.1 基础/)
    - [2.4.2 简单属性之间的相似度和相异度](https://changzhi.space/DM/简单属性之间的相似度和相异度/)
    - [2.4.3 数据对象之间的相异度](https://changzhi.space/DM/数据对象之间的相异度/)
    - [2.4.4 数据对象之间的相似度](https://changzhi.space/DM/数据对象之间的相似度/)
    - [2.4.5 邻近性度量的例子](https://changzhi.space/DM/邻近性度量的例子/)
    - [2.4.6 邻近度计算问题](https://changzhi.space/DM/邻近度计算问题/)
    - [2.4.7 选取正确的邻近性度量](https://changzhi.space/DM/选取正确的邻近性度量/)
- chap04 - 分类、决策树与模型评估
  - 1- [预备知识](https://changzhi.space/DM/预备知识/)
  - 2-[解决分类问题的一般方法](https://changzhi.space/DM/解决分类问题的一般方法/)
  - 3-[决策树归纳](https://changzhi.space/DM/决策树归纳/)
    - 4.3.1 [决策树的工作原理](https://changzhi.space/DM/决策树的工作原理/)
    - 4.3.2 [如何建立决策树](https://changzhi.space/DM/如何建立决策树/)
    - 4.3.3 [表示属性测试条件的方法](https://changzhi.space/DM/表示属性测试条件的方法/)
    - 4.3.4 [选择最佳划分的度量](https://changzhi.space/DM/选择最佳划分的度量/)
    - 4.3.5 [决策树归纳算法](https://changzhi.space/DM/决策树归纳算法/)
    - 4.3.7 [决策树归纳的特点](https://changzhi.space/DM/决策树归纳的特点/)
  - 4-[模型的过拟合](https://changzhi.space/DM/模型的过拟合/)
- chap05 - [分类：其他技术](https://changzhi.space/DM/分类-其他技术)
  - 1-[基于规则的分类器](https://changzhi.space/DM/基于规则的分类器/)
  - 2-[最近邻分类器](https://changzhi.space/DM/最近邻分类器/)
  - 3-[贝叶斯分类器](https://changzhi.space/DM/贝叶斯分类器/)
  - 4-[人工神经网络ANN](https://changzhi.space/DM/人工神经网络ANN/)
  - 5-[支持向量机SVM](https://changzhi.space/DM/支持向量机SVM/)
  - 6-[组合方法](https://changzhi.space/DM/组合方法/)

